{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "Written for MBA Love is Blind. Script to generate dating matching.\n",
    "\"\"\"\n",
    "\n",
    "from random import randrange, choice\n",
    "import pandas as pd\n",
    "\n",
    "__author__ = \"Huey Huilong Han\"\n",
    "__date__ = \"Last Update: May 14, 2020.\"\n",
    "\n",
    "###### load data and basic cleaning #####\n",
    "# read in data\n",
    "df = pd.read_csv(\"raw.csv\")\n",
    "\n",
    "# basic cleaning - drop rows and columns with all nans\n",
    "df = df.dropna(how='all', axis=0)\n",
    "df = df.dropna(how='all', axis=1)\n",
    "\n",
    "# rename columns\n",
    "df.columns = [\"personal_email\", \"anon_email\", \"gender\", \"interested_gender\", \"business_school\", \"year\", \"target_city\", \"interest\", \"age\"]\n",
    "\n",
    "# drop duplicates - some people enter the form twice\n",
    "df = df.drop_duplicates(subset='anon_email', keep=\"last\")\n",
    "\n",
    "\n",
    "\n",
    "###### wrangle locations #####\n",
    "# TODO: currently manually wrangling locations\n",
    "# need to improve Google Form to automate this\n",
    "# load city coordinates\n",
    "city_coordinates = pd.read_csv(\"uscities_coordinates/uscities.csv\")\n",
    "city_coordinates = city_coordinates[city_coordinates.population > 300000]\n",
    "\n",
    "unfound_cities = []\n",
    "for x in df.target_city.unique():\n",
    "    if x not in city_coordinates.city.to_list() and x != \"Undecided\" and x != \"Location does not matter\":\n",
    "        unfound_cities.append(x)\n",
    "\n",
    "df.target_city.replace({\"San Francisco / Bay Area\": \"San Francisco\", \"Philly\": \"Philadelphia\",\n",
    "                        \"Atlanta, DC, Houston\": \"Atlanta\", \"New York or San Francisco\": \"New York\",\n",
    "                        \"Phoenix / Scottsdale\": \"Phoenix\", \"Colorado\": \"Denver\", \"Washington DC\": \"Washington\",\n",
    "                        \"Washington, DC\": \"Washington\",\n",
    "                        \"London\": \"New York\", \"Toronto\": \"New York\", \"China\": \"New York\", \"Tokyo\": \"New York\",\n",
    "                        \"Sydney, Australia\": \"New York\"}, inplace=True)\n",
    "\n",
    "unfound_cities = []\n",
    "for x in df.target_city.unique():\n",
    "    if x not in city_coordinates.city.to_list() and x != \"Undecided\" and x != \"Location does not matter\":\n",
    "        unfound_cities.append(x)\n",
    "assert len(unfound_cities) == 0, \"Some locations without corresponding locations still exist!\"\n",
    "\n",
    "\n",
    "\n",
    "### clustering based on locations\n",
    "# define hub city\n",
    "# TODO: in the future, automate hub selection\n",
    "HUBS = {\"New York\": None, \"San Francisco\": None, \"Chicago\": None} # using these locations to approximate east, west and central\n",
    "\n",
    "# get coordinates\n",
    "for k in HUBS:\n",
    "    tmp = city_coordinates[city_coordinates.city == k]\n",
    "    HUBS[k] = (tmp.lat.values[0], tmp.lng.values[0])\n",
    "\n",
    "# clustering cities into hub cities\n",
    "clustering = {}\n",
    "for x in df.target_city.unique():\n",
    "    if x in HUBS or x == \"Undecided\" or x == \"Location does not matter\":\n",
    "        continue\n",
    "    else:\n",
    "        min_dist = 9999\n",
    "        min_city = None\n",
    "        tmp_lat = city_coordinates[city_coordinates.city == x].lat.values[0]\n",
    "        tmp_lng = city_coordinates[city_coordinates.city == x].lng.values[0]\n",
    "        for hub in HUBS:\n",
    "            tmp_dist = (abs(tmp_lat - HUBS[hub][0]) + abs(tmp_lng - HUBS[hub][1]))\n",
    "            if tmp_dist < min_dist:\n",
    "                min_dist = tmp_dist\n",
    "                min_city = hub\n",
    "        clustering[x] = min_city\n",
    "\n",
    "# clustering\n",
    "df.target_city.replace(clustering, inplace=True)\n",
    "\n",
    "# randomly assign \"undecided\" and \"location does not matter\" to hub\n",
    "# TODO: need to discuss this with Anna\n",
    "for index, row in df[(df.target_city == \"Undecided\") | (df.target_city == \"Location does not matter\")].iterrows():\n",
    "    rand_hub = choice(list(HUBS.keys()))\n",
    "    df.loc[index, 'target_city'] = rand_hub\n",
    "\n",
    "# create clusering groups\n",
    "location_groups = {}\n",
    "for l in df.target_city.unique():\n",
    "    location_groups[l] = df[df.target_city == l]\n",
    "\n",
    "# check if size matches original dataframe\n",
    "assert sum([location_groups[x].shape[0] for x in location_groups]) == df.shape[0], \"The sum of location subgroups does not match the original data!\"\n",
    "\n",
    "\n",
    "###### divide into gender-based groups #####\n",
    "# define groups based on interested and interested_gender group\n",
    "gender_loc_groups = {}\n",
    "\n",
    "# iterate through locations\n",
    "for l in location_groups:\n",
    "    # get dataframe\n",
    "    tmp = location_groups[l]\n",
    "    \n",
    "    # get heterosexual group\n",
    "    hetero = tmp[((tmp.gender == \"Male\") & (tmp.interested_gender == \"Female\")) | ((tmp.gender == \"Female\") & (tmp.interested_gender == \"Male\"))]    \n",
    "    key = l + \"_heterosexual\"\n",
    "    gender_loc_groups[key] = hetero\n",
    "    \n",
    "    # get male-male group\n",
    "    male_male = tmp[(tmp.gender == \"Male\") & (tmp.interested_gender == \"Male\")]\n",
    "    key = l + \"_male-male\"\n",
    "    gender_loc_groups[key] = male_male\n",
    "    \n",
    "    # get female-female group\n",
    "    female_female = tmp[(tmp.gender == \"Female\") & (tmp.interested_gender == \"Female\")]\n",
    "    key = l + \"_female-female\"\n",
    "    gender_loc_groups[key] = female_female\n",
    "\n",
    "    # get both group\n",
    "    ### TODO: figure out where to put \"both\" in the above category\n",
    "    both = tmp[tmp.interested_gender == \"Both\"]\n",
    "    key = l + \"_both\"\n",
    "    gender_loc_groups[key] = both\n",
    "\n",
    "# check if size matches original dataframe\n",
    "assert sum([gender_loc_groups[x].shape[0] for x in gender_loc_groups]) == df.shape[0], \"The sum of gender subgroups does not match the original data!\"\n",
    "\n",
    "\n",
    "###### certain groups are too small, if so, merge to another group #####\n",
    "\n",
    "THRESHOLD = 10 # NOTE: this is a parameter to be defined by user\n",
    "\n",
    "# delete groups with 0 members\n",
    "for x in list(gender_loc_groups):\n",
    "    if gender_loc_groups[x].shape[0] == 0:\n",
    "        del gender_loc_groups[x]\n",
    "\n",
    "# aggregate female-female since each location group is too small\n",
    "female_female = None\n",
    "for x in list(gender_loc_groups):\n",
    "    if x.split(\"_\")[1] == \"female-female\":\n",
    "        if female_female is None:\n",
    "            female_female = gender_loc_groups[x]\n",
    "            del gender_loc_groups[x]\n",
    "        else:\n",
    "            female_female = pd.concat([female_female, gender_loc_groups[x]])\n",
    "            del gender_loc_groups[x]\n",
    "gender_loc_groups[\"All_female-female\"] = female_female\n",
    "\n",
    "# aggregate small male-male locations group if each location is too small\n",
    "male_male = None\n",
    "for x in list(gender_loc_groups):\n",
    "    if x.split(\"_\")[1] == \"male-male\":\n",
    "        if gender_loc_groups[x].shape[0] > THRESHOLD:\n",
    "            continue\n",
    "        \n",
    "        if male_male is None:\n",
    "            male_male = gender_loc_groups[x]\n",
    "            del gender_loc_groups[x]\n",
    "        else:\n",
    "            male_male = pd.concat([male_male, gender_loc_groups[x]])\n",
    "            del gender_loc_groups[x]\n",
    "if male_male is not None:\n",
    "    gender_loc_groups[\"Other_male-male\"] = male_male\n",
    "\n",
    "# check if size matches original dataframe\n",
    "assert sum([gender_loc_groups[x].shape[0] for x in gender_loc_groups]) == df.shape[0], \"The sum of gender subgroups does not match the original data!\"\n",
    "\n",
    "# assign both to local heterosexual and corresponding gender group\n",
    "# e.g. New York male who clicked \"both\" would be assigned to New York hetero and New York male-male\n",
    "# New York female who clicked \"both\" would be assigned to New York hetero and New York female-female\n",
    "# TODO: discuss this with Anna\n",
    "for x in list(gender_loc_groups):\n",
    "    if x.split(\"_\")[1] == \"both\":\n",
    "        # get dataframe\n",
    "        tmp = gender_loc_groups[x]\n",
    "        \n",
    "        # extract location\n",
    "        location = x.split(\"_\")[0]\n",
    "        \n",
    "        # add to heterosexual group of that location\n",
    "        new_x = location + \"_heterosexual\"\n",
    "        gender_loc_groups[new_x] = pd.concat([gender_loc_groups[new_x], tmp])\n",
    "        \n",
    "        for index, row in tmp.iterrows():\n",
    "            if row.gender == \"Male\": # if male, add to male-male group of that location\n",
    "                new_x = location + \"_male-male\"\n",
    "                if new_x in gender_loc_groups.keys():\n",
    "                    gender_loc_groups[new_x] = pd.concat([gender_loc_groups[new_x], tmp])\n",
    "                else: # if that location does not exist, add to \"Other_male-male group\"\n",
    "                    new_x = location + \"Other_male-male\"\n",
    "                    gender_loc_groups[new_x] = pd.concat([gender_loc_groups[new_x], tmp])\n",
    "            \n",
    "            elif row.gender == \"Female\": # if female, add to female-female group\n",
    "                new_x = \"All_female-female\"\n",
    "                gender_loc_groups[new_x] = pd.concat([gender_loc_groups[new_x], tmp])\n",
    "            else:\n",
    "                raise ValueError(\"Gender not recognized!\")\n",
    "        \n",
    "        # delete this group from the dictionary\n",
    "        del gender_loc_groups[x]\n",
    "\n",
    "\n",
    "###### generate matching for each location-gender based group #####\n",
    "\n",
    "# load previous match\n",
    "prev_match = pd.read_csv(\"master_match_list.csv\")\n",
    "\n",
    "# basic cleaning - drop rows and columns with all nans\n",
    "prev_match = prev_match.dropna(how='all', axis=0)\n",
    "prev_match = prev_match.dropna(how='all', axis=1)\n",
    "\n",
    "# define min number of matches for every person\n",
    "HETERO_MIN_MATCH = 2 # NOTE: this is a parameter defined by user\n",
    "HOMO_MIN_MATCH = 2 # NOTE: this is a parameter defined by user\n",
    "\n",
    "\n",
    "# initialize matched_group\n",
    "matched_group = {}\n",
    "\n",
    "# iterate over gender_loc_groups\n",
    "for g in gender_loc_groups:\n",
    "    if g.split(\"_\")[1] == \"heterosexual\":\n",
    "        min_match = HETERO_MIN_MATCH\n",
    "    else:\n",
    "        min_match = HOMO_MIN_MATCH\n",
    "    \n",
    "    # get dataframe\n",
    "    tmp = gender_loc_groups[g]\n",
    "        \n",
    "    # process heterosexual\n",
    "    # heterosexual group needs to be processed different from other groups\n",
    "    # since male must match female (and vice versa), which is not the\n",
    "    # case for other groups\n",
    "    if g.split(\"_\")[1] == \"heterosexual\":\n",
    "        \n",
    "        # get people\n",
    "        males = tmp[tmp.gender == \"Male\"].anon_email.to_list()\n",
    "        females = tmp[tmp.gender == \"Female\"].anon_email.to_list()\n",
    "        \n",
    "        # calculate male-female ratio to generate dataframe\n",
    "        # rows are always >= cols\n",
    "        ratio = float(len(males))/float(len(females))\n",
    "        if ratio < 1: # more female than male\n",
    "            mat = pd.DataFrame(index=females, columns=males)\n",
    "        else: # more males than females\n",
    "            mat = pd.DataFrame(index=males, columns=females)\n",
    "        \n",
    "        # generate matrix\n",
    "        mat = pd.DataFrame(index=females, columns=males)\n",
    "        n_row = mat.shape[0]\n",
    "        n_col = mat.shape[1]        \n",
    "        \n",
    "    # process other groups\n",
    "    else:\n",
    "        # get people\n",
    "        people = tmp.anon_email.to_list()\n",
    "        \n",
    "        # generate adjacency matrix\n",
    "        mat = pd.DataFrame(index=people, columns=people)\n",
    "        n_row = mat.shape[0]\n",
    "        n_col = mat.shape[1]\n",
    "        \n",
    "    ##### generate solution #####\n",
    "    \n",
    "    # randomly shuffle the data\n",
    "    mat = mat.sample(frac=1)\n",
    "\n",
    "    # generate col num range to iterate over\n",
    "    tmp_index = list(range(mat.shape[1])) * (100 * min_match) # debug\n",
    "    \n",
    "    # iterate on rows\n",
    "    for index, row in mat.iterrows():\n",
    "        # iterate over index list\n",
    "        for i in tmp_index:\n",
    "\n",
    "            # if have enough matches break the loop\n",
    "            if row.sum() >= min_match:\n",
    "                break\n",
    "\n",
    "            # pass if if it's the same person\n",
    "            if index == row.index[i]:\n",
    "                continue\n",
    "\n",
    "            # pass if this match exists in previous matches\n",
    "            p1 = index\n",
    "            p2 = row.index[i]\n",
    "            if prev_match[(prev_match.To == p1) & (prev_match.From == p2)].shape[0] != 0:\n",
    "                continue\n",
    "            \n",
    "            # pass if it's non-heterosexual and the other person has too many matches\n",
    "            if g.split(\"_\")[1] != \"heterosexual\":\n",
    "                if mat[row.index[i]].sum() > min_match:\n",
    "                    continue\n",
    "\n",
    "            # if all conditions pass, add matching to adjacency matrix\n",
    "            mat.loc[index, row.index[i]] = 1\n",
    "            if g.split(\"_\")[1] != \"heterosexual\":\n",
    "                mat.loc[row.index[i], index] = 1\n",
    "\n",
    "            # remove index from tmp_index\n",
    "            tmp_index.remove(i)\n",
    "            \n",
    "    # add to matched group\n",
    "    matched_group[g] = mat\n",
    "\n",
    "    \n",
    "###### generate output dataframe for emailing #####\n",
    "\n",
    "output_df = {}\n",
    "\n",
    "for g in matched_group:    \n",
    "    for index, row in matched_group[g].iterrows():\n",
    "        if index not in output_df.keys():\n",
    "            output_df[index] = set(row.dropna().index.to_list()) # using set to ensure unique values\n",
    "        else: # else handles bisexual\n",
    "            output_df[index] = output_df[index].union(set(row.dropna().index.to_list())) # using set to ensure unique values\n",
    "    \n",
    "    \n",
    "    # if heterosexual, add columns as well\n",
    "    if g.split(\"_\")[1] == \"heterosexual\":\n",
    "        for index in matched_group[g].columns:\n",
    "            column = matched_group[g][index]\n",
    "            if index not in output_df.keys():\n",
    "                output_df[index] = set(column.dropna().index.to_list()) # using set to ensure unique values\n",
    "            else: # else handles bisexual\n",
    "                output_df[index] = output_df[index].union(set(column.dropna().index.to_list())) # using set to ensure unique values\n",
    "\n",
    "# construct dataframe\n",
    "output_df = pd.DataFrame.from_dict(output_df, orient='index')\n",
    "output_df = output_df.dropna(axis=1, how='all')\n",
    "columns = [\"match_{}\".format(i+1) for i in range(len(output_df.columns))]\n",
    "output_df.columns = columns\n",
    "output_df.index.set_names(\"emailee\", inplace=True)\n",
    "\n",
    "# output master match df\n",
    "DATE = '2020-05-16'\n",
    "ROUND = 'Round X'\n",
    "\n",
    "master_match_df = {}\n",
    "master_match_df['To'] = []\n",
    "master_match_df['From'] = []\n",
    "master_match_df['Date'] = []\n",
    "master_match_df['Round'] = []\n",
    "for index, row in output_df.iterrows():\n",
    "    match_list = row.dropna().to_list()\n",
    "    master_match_df['From']+= match_list\n",
    "    master_match_df['To']+=[index for _ in range(len(match_list))]\n",
    "    master_match_df['Date'] = DATE\n",
    "    master_match_df['Round'] = ROUND    \n",
    "pd.DataFrame(master_match_df).to_csv(\"master_match_new_batch.csv\", index=False)\n",
    "\n",
    "\n",
    "# replace email address with personal info, for emailing purposes\n",
    "# read in data\n",
    "tmp = pd.read_csv(\"raw.csv\")\n",
    "tmp = tmp.dropna(how='all', axis=0)\n",
    "tmp = tmp.dropna(how='all', axis=1)\n",
    "tmp.columns = [\"personal_email\", \"anon_email\", \"gender\", \"interested_gender\", \"business_school\", \"year\", \"target_city\", \"interest\", \"age\"]\n",
    "tmp = tmp.drop_duplicates(subset='anon_email', keep=\"last\")\n",
    "\n",
    "# anon email replacement\n",
    "emailee_replacement = tmp[[\"anon_email\", \"personal_email\"]].set_index(\"anon_email\")\n",
    "emailee_replacement = emailee_replacement.to_dict()['personal_email']\n",
    "output_df.index = output_df.index.map(lambda x: emailee_replacement[x])\n",
    "\n",
    "# construct concat string\n",
    "tmp[\"concat_info\"] = tmp[\"anon_email\"] + \" - \" + tmp[\"gender\"] + \" - \" + tmp[\"target_city\"] + \" - \" + tmp[\"interest\"]\n",
    "tmp.set_index(\"anon_email\", inplace=True)\n",
    "tmp = tmp[\"concat_info\"]\n",
    "tmp = tmp.transpose().to_dict()\n",
    "\n",
    "# replace values\n",
    "output_df.replace(tmp, inplace=True)\n",
    "\n",
    "###### writing to disk #####\n",
    "output_df.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
